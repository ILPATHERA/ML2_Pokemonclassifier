{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOp+U5or+uANixtfxuz4lyt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ILPATHERA/ML2_Pokemoncreator/blob/main/ML2_Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My Machine Learning 2 Image Classification Model"
      ],
      "metadata": {
        "id": "TGwpQwI0JKzp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "Welcome to this Jupyter Notebook, which focuses on the classification of Pok√©mon images using a machine learning model. In this project, we will utilize a Pok√©mon dataset to train an image classification model. The trained model will then be used to classify new Pok√©mon images.\n"
      ],
      "metadata": {
        "id": "k1-Df3QVbHXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset: Pok√©mon Images\n",
        "\n",
        "Our dataset consists of a variety of Pok√©mon images, with each image associated with a specific Pok√©mon. The goal is to create a model capable of identifying these Pok√©mon based on their visual characteristics. We will divide the dataset into training and testing sets."
      ],
      "metadata": {
        "id": "WyMCLZ7tbR-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "S-YHlZVkJb6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I could have included all imports which were used in one cell. However, since I like to be able to see in the respective cell which import is needed, I will import this in the respective cell."
      ],
      "metadata": {
        "id": "2yIdXgN5d-qX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "id": "QfdpMV14JWkK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I found the dataset on Kaggle. To use this directly, we need the API of Kaggle. In my GitHub repository there is a file called kaggle.json. Download it and upload it below."
      ],
      "metadata": {
        "id": "s2FF32nLbk9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload kaggle.json"
      ],
      "metadata": {
        "id": "2anSHmup4r4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "3ytiVLUW4nnX",
        "outputId": "5bdee6ef-f91e-4a7d-ade2-3fe0369e68a2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a884738b-b937-486d-b8c3-c8fbffc1cf19\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a884738b-b937-486d-b8c3-c8fbffc1cf19\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"simoneantoniosommer\",\"key\":\"ccbbebbff4f40fa13f5b9024966cb78c\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup Kaggle API"
      ],
      "metadata": {
        "id": "lW5qXrUu6CDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lha kaggle.json\n",
        "!pip install -q kaggle # installing the kaggle package\n",
        "!mkdir -p ~/.kaggle # creating .kaggle folder where the key should be placed\n",
        "!cp kaggle.json ~/.kaggle/ # move the key to the folder\n",
        "!pwd # checking the present working directory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cJa07_X4x0s",
        "outputId": "1532f1a3-5582-4b94-b584-231e5f8170ef"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 75 May 28 17:38 kaggle.json\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Giving permission to file"
      ],
      "metadata": {
        "id": "FhW8SkGW6Qyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "CZmvL1p_42N7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we check the connection to Kaggle. If the following is a list of datasets, then the connection to the Kaggle API has succeeded."
      ],
      "metadata": {
        "id": "24rkm1gc6VKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gox2b4L44w9",
        "outputId": "c687230a-7796-4f17-a6cf-9574637f8b01"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                                   title                                                size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "--------------------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "arnabchaki/data-science-salaries-2023                                 Data Science Salaries 2023 üí∏                         25KB  2023-04-13 09:55:16          21773        603  1.0              \n",
            "mauryansshivam/netflix-ott-revenue-and-subscribers-csv-file           Netflix OTT Revenue and Subscribers (CSV File)        2KB  2023-05-13 17:40:23            916         24  1.0              \n",
            "fatihb/coffee-quality-data-cqi                                        Coffee Quality Data (CQI May-2023)                   22KB  2023-05-12 13:06:39           2352         56  1.0              \n",
            "darshanprabhu09/stock-prices-for                                      Stock prices of Amazon , Microsoft , Google, Apple   85KB  2023-05-16 15:17:16           1025         31  1.0              \n",
            "adityaramachandran27/world-air-quality-index-by-city-and-coordinates  World Air Quality Index by City and Coordinates     372KB  2023-05-07 07:29:26            967         28  1.0              \n",
            "anxods/spotify-top-50-playlist-songs-anxods                           Spotify Top 50 Playlist Songs | @anxods              66KB  2023-05-28 11:40:44            875         29  0.9411765        \n",
            "bilalwaseer/google-stocks-complete                                    Google Stocks Complete                               98KB  2023-05-16 18:17:17            528         23  1.0              \n",
            "iammustafatz/diabetes-prediction-dataset                              Diabetes prediction dataset                         734KB  2023-04-08 06:11:45          11301        165  1.0              \n",
            "tanisha1416/aqi-bangalore-2023                                        Smog City Diaries: Unveiling Air Quality Trendsüìà      4KB  2023-05-25 04:18:15            335         23  1.0              \n",
            "mohithsairamreddy/salary-data                                         Salary_Data                                          17KB  2023-05-18 14:05:19           1426         38  0.88235295       \n",
            "desalegngeb/students-exam-scores                                      Students Exam Scores: Extended Dataset              695KB  2023-04-14 00:15:38           9051        179  1.0              \n",
            "utkarshx27/lovoo-dating-app-dataset                                   Dating App Fame & Behavior                          572KB  2023-05-14 12:26:00            621         21  1.0              \n",
            "ashpalsingh1525/imdb-movies-dataset                                   IMDB movies dataset                                   3MB  2023-04-28 23:18:15           2517         55  1.0              \n",
            "radheshyamkollipara/bank-customer-churn                               Bank Customer Churn                                 307KB  2023-04-28 16:32:01           2551         41  1.0              \n",
            "danbraswell/temporary-us-births                                       US Births üë∂ by Year, State, and Education Level      60KB  2023-05-08 23:15:33           1034         22  1.0              \n",
            "utkarshx27/fashion-ecommerce-user-data                                Fashion E-commerce User Data                          2MB  2023-05-19 11:04:09            820         29  1.0              \n",
            "riybot/riyadh-cafes                                                   Riyadh Cafes                                        251KB  2023-05-22 22:24:22            577         25  1.0              \n",
            "arnabchaki/tripadvisor-reviews-2023                                   Tripadvisor Reviews 2023 ‚≠ê                           22MB  2023-05-17 08:26:35            411         23  1.0              \n",
            "utkarshx27/inflation-rate-in-asia                                     Inflation Rate in Asia                                3KB  2023-05-13 17:41:29           1051         34  1.0              \n",
            "utkarshx27/breast-cancer-wisconsin-diagnostic-dataset                 Breast Cancer Wisconsin Diagnostic Dataset           48KB  2023-05-10 04:40:33            679         27  1.0              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the dataset \"pokemon-images-and-types\" is downloaded, unzipped and saved to the current working directory of the Jupyter notebook. This dataset contains images of Pok√©mon along with their type information.\n",
        "\n",
        "This is the dataset we will use in this Jupyter Notebook."
      ],
      "metadata": {
        "id": "7yHN5Idh6ZX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d vishalsubbiah/pokemon-images-and-types\n",
        "!unzip /content/pokemon-images-and-types.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7Y-GUKX5KTA",
        "outputId": "5fd9aa05-4168-4a7a-f608-78076fb3a464"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pokemon-images-and-types.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  /content/pokemon-images-and-types.zip\n",
            "replace images/images/abomasnow.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our dataset consists of a CSV file and a folder with the images in JPG and PNG format. So that we can connect this accordingly, we add a column to the DF and deposit the respective path of the image."
      ],
      "metadata": {
        "id": "T7wp3yb5lY6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "#Create df\n",
        "df = pd.read_csv('/content/pokemon.csv')\n",
        "\n",
        "# Path to the images\n",
        "image_folder = '/content/images/images'\n",
        "\n",
        "# Create a dictionary to map image names to their corresponding paths\n",
        "image_dict = {}\n",
        "for file in os.listdir(image_folder):\n",
        "    image_dict[os.path.splitext(file)[0]] = os.path.join(image_folder, file)\n",
        "\n",
        "# Create a new column for the image path in the DataFrame\n",
        "df['image_path'] = df['Name'].map(image_dict)\n",
        "\n",
        "# Display the DataFrame\n",
        "df.head()\n",
        "#df.tail()\n",
        "\n",
        "from IPython.display import display, Image\n",
        "\n",
        "# DataFrame mit den Bildpfaden\n",
        "df = pd.read_csv('/content/pokemon.csv')\n",
        "\n",
        "# Funktion zum Anzeigen von Bildern in der Tabelle\n",
        "def display_image(image_path):\n",
        "    display(Image(filename=image_path))\n",
        "\n",
        "# Anzeigen der Tabelle mit Bildern\n",
        "df['image'] = df['image_path'].apply(display_image)\n",
        "display(df)\n"
      ],
      "metadata": {
        "id": "vIflejGci91y",
        "outputId": "b52d480f-1932-4b51-bd54-95f03b210486",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'image_path'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-45b77f3b5977>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Anzeigen der Tabelle mit Bildern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'image_path'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "fu2KtlhOl0u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transforming the Data"
      ],
      "metadata": {
        "id": "aTslYoOcJhy_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Custom Dataset and DataLoading"
      ],
      "metadata": {
        "id": "oemxhx4OJu8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path = \"/kaggle/input/image-classification-screening/train\"\n",
        "test_data_path = \"/kaggle/input/image-classification-screening/test\"\n",
        "\n",
        "\n",
        "train_img_paths = []\n",
        "\n",
        "for data_path in glob.glob(train_data_path+'/*'):\n",
        "    #print(data_path)\n",
        "    train_img_paths.append(glob.glob(data_path))\n",
        "    \n",
        "train_img_paths = [x[0] for x in train_img_paths]\n",
        "random.shuffle(train_img_paths)\n",
        "\n",
        "train_img_paths , valid_img_paths = train_img_paths[:int(0.8* len(train_img_paths))], train_img_paths[int(0.8*len(train_img_paths)):]\n",
        "\n",
        "\n",
        "test_img_paths = []\n",
        "for data_path in glob.glob(test_data_path + '/*'):\n",
        "    test_img_paths.append(glob.glob(data_path))\n",
        "\n",
        "test_img_paths = [x[0] for x in test_img_paths]\n",
        "print(\"Train size: {}\\nValid size: {}\\nTest size: {}\".format(len(train_img_paths), len(valid_img_paths), len(test_img_paths)))"
      ],
      "metadata": {
        "id": "KZ2EkhnnJ1pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing Results\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I0OLEaj3J7eE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "YnKABOO6J_aD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining Layers"
      ],
      "metadata": {
        "id": "hakBOhz9KBEm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "MAY-eBWbKcGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training\n",
        "\n",
        "For the classification of Pok√©mon images, we will employ a Convolutional Neural Network (CNN). CNNs are particularly well-suited for detecting visual patterns in images. We will train the CNN model using the training dataset. During the training process, the model's weights will be adjusted to learn the visual features of the different Pok√©mon.\n",
        "\n",
        "## Model Evaluation\n",
        "\n",
        "Once the model has been trained, it is crucial to assess its performance. We will test the trained model on the"
      ],
      "metadata": {
        "id": "AnSINLi9bbfr"
      }
    }
  ]
}